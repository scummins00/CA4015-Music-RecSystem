%Recommender-systems book
@book{ekstrand2011collaborative,
  title={Collaborative filtering recommender systems},
  author={Ekstrand, Michael D and Riedl, John T and Konstan, Joseph A},
  year={2011},
  publisher={Now Publishers Inc}
}

%HETREC 2011 Citation
@inproceedings{cantador2011second,
  title={Second workshop on information heterogeneity and fusion in recommender systems (HetRec2011)},
  author={Cantador, Iv{\'a}n and Brusilovsky, Peter and Kuflik, Tsvi},
  booktitle={Proceedings of the fifth ACM conference on Recommender systems},
  pages={387--388},
  year={2011}
}

%========================ORIGINAL PAPERS FOR DIFF METHODS================
%Original content based rec sys
@article{marko1997,
author = {Balabanovi\'{c}, Marko and Shoham, Yoav},
title = {Fab: Content-Based, Collaborative Recommendation},
year = {1997},
issue_date = {March 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/245108.245124},
doi = {10.1145/245108.245124},
journal = {Commun. ACM},
month = {mar},
pages = {66–72},
numpages = {7}
}

%Original demographic based filtering
@article{pazzani1999framework,
  title={A framework for collaborative, content-based and demographic filtering},
  author={Pazzani, Michael J},
  journal={Artificial intelligence review},
  volume={13},
  number={5},
  pages={393--408},
  year={1999},
  publisher={Springer}
}

%Original Utility based 
@article{guttman1998agent,
  title={Agent-mediated electronic commerce: A survey},
  author={Guttman, Robert H and Moukas, Alexandros G and Maes, Pattie},
  journal={The Knowledge Engineering Review},
  volume={13},
  number={2},
  pages={147--159},
  year={1998},
  publisher={Cambridge University Press}
}
%=======================================================================

%========================COLLABORATIVE FILTERING SURVEYS================
%Collaborative filtering survey1
@article{thorat2015survey,
  title={Survey on collaborative filtering, content-based filtering and hybrid recommendation system},
  author={Thorat, Poonam B and Goudar, RM and Barve, Sunita},
  journal={International Journal of Computer Applications},
  volume={110},
  number={4},
  pages={31--36},
  year={2015},
  publisher={Foundation of Computer Science}
}

@article{su2009survey,
  title={A survey of collaborative filtering techniques},
  author={Su, Xiaoyuan and Khoshgoftaar, Taghi M},
  journal={Advances in artificial intelligence},
  volume={2009},
  year={2009},
  publisher={Hindawi}
}

 @article{Elahi_Ricci_Rubens_2016, title={A survey of active learning in collaborative filtering recommender systems},
 volume={20}, 
 ISSN={1574-0137}, 
 DOI={https://doi.org/10.1016/j.cosrev.2016.05.002}, 
 journal={Computer Science Review},
 author={Elahi, Mehdi and Ricci, Francesco and Rubens, Neil}, 
 year={2016}, 
 pages={29–50}
 }

%======================================================================

%========================MATRIX FACTORISATION===============================

%Paper about swam methods for loss function in MF
 @inproceedings{Laishram_Sahu_Padmanabhan_Udgata_2016, 
 place={Cham}, 
 series={Lecture Notes in Computer Science}, 
 booktitle="Collaborative Filtering, Matrix Factorization and Population Based Search: The Nexus Unveiled", 
 ISBN={978-3-319-46675-0}, 
 DOI={10.1007/978-3-319-46675-0_39}, 
 publisher={Springer International Publishing}, 
 author={Laishram, Ayangleima and Sahu, Satya Prakash and Padmanabhan, Vineet and Udgata, Siba Kumar}, 
 editor={Hirose, Akira and Ozawa, Seiichi and Doya, Kenji and Ikeda, Kazushi and Lee, Minho and Liu, Derong}, year={2016}, 
 pages={352–361}, 
 collection={Lecture Notes in Computer Science}
 }

%paper all about in-depth matrix factorisation
 @article{Koren_Bell_Volinsky_2009, title={Matrix Factorization Techniques for Recommender Systems}, volume={42}, ISSN={1558-0814}, DOI={10.1109/MC.2009.263}, abstractNote={As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels.}, number={8}, journal={Computer}, author={Koren, Yehuda and Bell, Robert and Volinsky, Chris}, year={2009}, month={Aug}, pages={30–37} }

 %paper describing ALS
 @InProceedings{cichocki2007,
author="Cichocki, Andrzej
and Zdunek, Rafal",
editor="Liu, Derong
and Fei, Shumin
and Hou, Zengguang
and Zhang, Huaguang
and Sun, Changyin",
title="Regularized Alternating Least Squares Algorithms for Non-negative Matrix/Tensor Factorization",
booktitle="Advances in Neural Networks -- ISNN 2007",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="793--802",
isbn="978-3-540-72395-0"
}

%paper describing sgd
@inproceedings{Rainer2011,
author = {Gemulla, Rainer and Nijkamp, Erik and Haas, Peter J. and Sismanis, Yannis},
title = {Large-Scale Matrix Factorization with Distributed Stochastic Gradient Descent},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020426},
doi = {10.1145/2020408.2020426},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {69–77},
numpages = {9},
keywords = {stochastic gradient descent, recommendation system, mapreduce, distributed matrix factorization},
location = {San Diego, California, USA},
series = {KDD '11}
}

%=======================GREAT WORK BY AIOLLI=====================

@inproceedings{aiolli2013preliminary,
  title={A Preliminary Study on a Recommender System for the Million Songs Dataset Challenge.},
  author={Aiolli, Fabio},
  booktitle={IIR},
  pages={73--83},
  year={2013},
  organization={Citeseer}
}

%=======================LONG TAIL PROBLEM DESCRIPTION=====================

@book{anderson2006long,
  title={The long tail: Why the future of business is selling less of more},
  author={Anderson, Chris},
  year={2006},
  publisher={Hachette Books}
}


%====================DEEP NEURAL NETWORKS=========================

%youtube neural net
 @inproceedings{Covington_Adams_Sargin_2016, place={New York, NY, USA}, series={RecSys ’16}, title={Deep Neural Networks for YouTube Recommendations}, ISBN={978-1-4503-4035-9}, url={https://doi.org/10.1145/2959100.2959190}, DOI={10.1145/2959100.2959190}, abstractNote={YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.}, booktitle={Proceedings of the 10th ACM Conference on Recommender Systems}, publisher={Association for Computing Machinery}, author={Covington, Paul and Adams, Jay and Sargin, Emre}, year={2016}, month={Sep}, pages={191–198}, collection={RecSys ’16} }

%google wide and large
@inproceedings{Cheng_Koc2016, place={New York, NY, USA}, series={DLRS 2016}, title={Wide &amp; Deep Learning for Recommender Systems}, ISBN={978-1-4503-4795-2}, url={https://doi.org/10.1145/2988450.2988454}, DOI={10.1145/2988450.2988454}, abstractNote={Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide & Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide & Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.}, booktitle={Proceedings of the 1st Workshop on Deep Learning for Recommender Systems}, publisher={Association for Computing Machinery}, author={Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal}, year={2016}, month={Sep}, pages={7–10}, collection={DLRS 2016} }

%dnn rec sys survey
 @article{Zhang_Yao_Sun_Tay_2019, title={Deep Learning Based Recommender System: A Survey and New Perspectives}, volume={52}, ISSN={0360-0300}, DOI={10.1145/3285029}, abstractNote={With the growing volume of online information, recommender systems have been an effective strategy to overcome information overload. The utility of recommender systems cannot be overstated, given their widespread adoption in many web applications, along with their potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also to the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. The field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning-based recommender systems. More concretely, we provide and devise a taxonomy of deep learning-based recommendation models, along with a comprehensive summary of the state of the art. Finally, we expand on current trends and provide new perspectives pertaining to this new and exciting development of the field.}, number={1}, journal={ACM Computing Surveys}, author={Zhang, Shuai and Yao, Lina and Sun, Aixin and Tay, Yi}, year={2019}, month={Feb}, pages={5:1-5:38} }

%========================ADAGRAD PAPER========
@article{lydia2019adagrad,
  title={Adagrad—an optimizer for stochastic gradient descent},
  author={Lydia, Agnes and Francis, Sagayaraj},
  journal={Int. J. Inf. Comput. Sci},
  volume={6},
  number={5},
  year={2019}
}
